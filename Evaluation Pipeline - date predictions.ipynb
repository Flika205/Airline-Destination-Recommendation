{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The prediction parquet to be evaluated needs to contain trackId, model_output, y_true columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formatted_ddf: org.apache.spark.sql.DataFrame = [y_true: int, model_output: float]"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.SQLTransformer\n",
    "import org.apache.spark.mllib.tree.loss.LogLoss\n",
    "\n",
    "val predictions_dir = \n",
    "val model_name = \"date_predictions.parquet/*\"\n",
    "val ddf = spark.read.parquet(s\"${predictions_dir}${model_name}\")\n",
    "\n",
    "val formatted_ddf = ddf.selectExpr(\"target as y_true\",\" cast(split(split(CAST(probability as STRING), '[,]')[1], ']')[0] as float) as model_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions_ddf: org.apache.spark.sql.DataFrame = [y_true: double, model_output: double ... 1 more field]"
     ]
    }
   ],
   "source": [
    "val predictions_ddf = formatted_ddf.selectExpr(\"cast(y_true as double) y_true\", \n",
    "                                    \"cast(model_output as double) model_output\",\n",
    "                                    \"cast(model_output>0.5 as double) predicted_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+-------------------+\n",
      "|summary|            y_true|        model_output|    predicted_class|\n",
      "+-------+------------------+--------------------+-------------------+\n",
      "|  count|              1019|                1019|               1019|\n",
      "|   mean|0.2561334641805692| 0.24639845547654152|0.21786064769381747|\n",
      "| stddev|0.4367107428676595| 0.32786620034097463|0.41299487932146206|\n",
      "|    min|               0.0|2.842412504833191...|                0.0|\n",
      "|    max|               1.0|   0.997983992099762|                1.0|\n",
      "+-------+------------------+--------------------+-------------------+"
     ]
    }
   ],
   "source": [
    "predictions_ddf.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metricsMulti: org.apache.spark.mllib.evaluation.MulticlassMetrics = org.apache.spark.mllib.evaluation.MulticlassMetrics@3c359eff"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "import org.apache.spark.mllib.regression.LabeledPoint\n",
    "import org.apache.spark.mllib.util.MLUtils\n",
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics\n",
    "\n",
    "val predictionAndLabels = predictions_ddf.select(\"model_output\", \"y_true\").rdd.map(row => \n",
    "  (row.getAs[Double](0), row.getAs[Double](1)))\n",
    "val metrics = new BinaryClassificationMetrics(predictionAndLabels)\n",
    "\n",
    "val predictionAndClasses = predictions_ddf.select(\"predicted_class\", \"y_true\").rdd.map(row => \n",
    "  (row.getAs[Double](0), row.getAs[Double](1)))\n",
    "val metricsMulti = new MulticlassMetrics(predictionAndClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8694798822374877"
     ]
    }
   ],
   "source": [
    "println(s\"Accuracy = ${metricsMulti.accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8658471839467836"
     ]
    }
   ],
   "source": [
    "println(s\"F1 score: ${metricsMulti.weightedFMeasure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 0.9493575551714029"
     ]
    }
   ],
   "source": [
    "println(\"Area under ROC = \" + metrics.areaUnderROC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (Spark)",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  },
  "name": "sia_evaluation",
  "notebookId": 433
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
